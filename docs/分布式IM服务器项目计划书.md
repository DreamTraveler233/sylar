# 分布式 IM 服务器项目计划书（基于 XinYu-IM-Backend 现状演进）

日期：2026-01-06

## 1. 背景与目标

### 1.1 背景
当前工程为单体 IM 服务端，可同时提供：HTTP API、WebSocket 长连接网关、媒体上传、联系人/群组/会话/消息等业务能力。工程内部已具备若干“分布式化积木”，例如：
- **WebSocket 服务与网关模块**（`WsGatewayModule`，支持推送事件与消息）
- **Rock 协议 / RPC Server**（`RockServer`，以及 Rock 相关协议实现）
- **ZooKeeper 服务发现**（`ZKServiceDiscovery`，支持注册/查询/监听）

为了支持多实例水平扩展、按业务域拆分、服务自治与故障隔离，需要对现有单体逐步演进为分布式架构。

### 1.2 总体目标（可验收）
在不推翻现有实现的前提下，用“渐进式拆分”的方式达到：
1. **网关可水平扩容**：WebSocket/HTTP Gateway 支持多实例部署，登录态与路由可用。
2. **消息链路分层**：消息写入、投递、离线存储、ACK/重试具备清晰边界。
3. **服务注册与发现可用**：服务实例通过 ZooKeeper 注册，调用方可发现与负载均衡。
4. **基础可观测与运维**：日志、关键指标、链路追踪（最小集）可支撑线上排障。
5. **灰度与兼容**：客户端协议与主要 API 尽量保持兼容，允许按阶段替换。

### 1.3 非目标（本计划不强行覆盖）
- 立即引入复杂的服务网格或全量微服务治理平台。
- 一次性重写全部业务逻辑为“纯领域模型”。
- 立刻替换现有存储方案（MySQL/Redis/本地存储）为新中间件。

## 2. 现状评估（基于当前代码组件）

### 2.1 已具备能力（可直接复用）
- **网络框架**：HTTP、WebSocket、TCP Server、协议解析（Ragel 生成 parser）。
- **协程/调度/线程池**：用于实现高并发与异步任务。
- **服务发现**：ZooKeeper 客户端与服务发现封装（注册/监听/查询）。
- **内部 RPC 雏形**：RockServer + ModuleMgr（可以承载服务间调用/通知）。
- **基础设施适配**：MySQL/Redis/SQLite 封装、Repository 实现、存储适配。

### 2.2 主要单体耦合点（后续拆分重点）
- `bootstrap/main.cpp` 里把 API、应用服务、仓储/存储、WS 网关“集中装配”，导致：
  - 网关与业务服务强耦合
  - 业务进程难以按域拆分
- `WsGatewayModule::PushToUser/PushImMessage` 默认在同进程内访问会话/连接状态；分布式下需要“跨网关路由”。
- 消息写入、投递、会话更新、推送通知在同一服务内完成；拆分后需要明确“消息写入服务 / 投递服务 / 在线状态服务”等职责。

## 3. 目标架构蓝图（渐进式）

### 3.0 总体架构（建议部署形态）

> 说明：这是目标形态的“分层视图”，实现路径以 4 章的里程碑为准（先网关拆分，再在线路由，再消息服务拆分）。

```
┌─────────────────────────────────────────────────┐
│                 负载均衡层 (Nginx/LVS)           │
└─────────────┬──────────────┬────────────────────┘
    │              │
    ┌─────────▼────┐  ┌─────▼─────────┐
    │  API 网关层   │  │  长连接网关层  │
    │ (REST/HTTP)   │  │ (WebSocket)   │
    └──────┬────────┘  └──────┬────────┘
      │                  │
    ┌──────┴──────────────────┴──────┐
    │         服务发现层              │
    │        (ZooKeeper)              │
    └──────┬──────────┬──────────────┘
      │          │
    ┌──────▼────┐  ┌──▼─────────┐
    │ 用户服务   │  │ 消息服务    │   ...（群组/联系人/媒体等）
    └───────────┘  └────────────┘
      │          │
    ┌──────▼──────────▼───────────────────────────┐
    │                 数据层                        │
    │           MySQL / Redis / （可选 MQ）          │
    └──────────────────────────────────────────────┘
```

### 3.1 进程/服务划分（建议最小可行拆分）
1. **gateway-http**（HTTP API Gateway）
   - 负责 REST API、鉴权、限流、聚合
   - 调用后端业务服务（RPC）
2. **gateway-ws**（WebSocket Gateway）
   - 负责连接管理、心跳、推送、事件分发
   - 依赖在线状态/路由服务进行跨节点推送
3. **svc-user**（用户/认证服务）
   - 登录、鉴权（JWT）、用户资料
4. **svc-contact**（联系人/关系服务）
5. **svc-group**（群组服务）
6. **svc-message**（消息服务：写入/查询）
7. **svc-presence**（在线状态与路由服务）
   - 记录 `user_id -> gateway_ws_instance` 映射
   - 支持跨网关推送定位
8. **svc-media**（媒体上传/下载/转存）

> 说明：以上可按里程碑逐步落地；前 3~4 个服务先行即可形成闭环。

### 3.2 服务间通信
- 优先复用现有 **Rock RPC** 作为内部通信（短期）
- 中长期可引入 gRPC（可选）

### 3.3 数据与一致性策略（建议）
- **强一致需求**：用户登录态、关键权限校验（以 user/auth 为准）。
- **最终一致**：会话列表刷新、消息已读回执等。
- **在线状态**：以 Redis 为主存（带 TTL），必要时写入 ZK/DB 作为辅助（可选）。

### 3.4 核心链路（端到端视角）

**A. 建连与鉴权（WebSocket）**
1. 客户端连接 `gateway-ws`（LB 负责分配）
2. 网关验证 JWT/Token（复用现有 JWT 逻辑）
3. 网关上报在线状态：`user_id -> gateway_instance_id`（写入 `svc-presence`/Redis）

**B. 发送消息（私聊/群聊）**
1. 客户端发消息到 `gateway-ws`
2. 网关将消息路由到 `svc-message`（短期 Rock RPC；中期可 MQ + RPC）
3. `svc-message` 做幂等（按 msg_id 或 client_seq 去重）、持久化
4. `svc-message` 通知投递：查询 `svc-presence` 得到目标用户所在网关实例
5. 目标 `gateway-ws` 推送给用户所有在线设备（多端同步）
6. 若用户离线：写入离线队列/离线表，待下次上线或拉取同步

**C. 同步与补偿**
- 客户端按 `seq_id`/时间窗口拉取缺失消息（`svc-message` 提供 sync/query）
- 推送失败可降级为轮询拉取（保证最终可达）

## 4. 分阶段实施计划（里程碑 + 交付物）

> 时间以“周”为单位，可根据团队人力调整。

### 阶段 0：基线与拆分准备（第 1 周）
**目标**：为拆分创造工程与运维基础，确保后续迭代可控。
- 交付物
  - 顶层文档：本计划书
  - 多进程运行脚本（最小）：可同时拉起 2 个网关实例 + 单体业务实例
  - 服务发现约定：服务名、实例 ID、注册路径规范
  - 配置规范：每个进程独立 `server.yaml/workers.yaml`（可复用现有）
- 验收标准
  - 单体 `im_server` 仍可运行
  - ZooKeeper 注册/查询 demo 可在本地稳定运行

### 阶段 1：网关分离（第 2~3 周）
**目标**：把“连接入口”与“业务实现”分离，形成可横向扩容的网关。
- 工作内容
  - 拆出 `gateway-ws` 进程：只保留 WS 连接、鉴权握手、心跳、推送协议
  - 拆出 `gateway-http` 进程：REST API 入口
  - 引入服务发现：网关发现后端服务地址
- 交付物
  - 新可执行文件：`bin/gateway_ws`、`bin/gateway_http`（或等价命名）
  - ZK 注册：网关实例上线后注册可见
- 验收标准
  - 单用户登录 + WS 建连 + 收到推送事件可用
  - 网关启动 2 实例，客户端可连任一实例

### 阶段 2：在线状态与路由（第 4 周）
**目标**：解决“跨网关推送”的核心问题。
- 工作内容
  - 新增 `svc-presence`：记录在线用户与所在 WS 网关实例
  - 网关 WS 在用户上线/下线时更新 presence
  - `PushToUser` 改为：先查路由（presence），再将推送发往目标网关实例（RPC）
- 交付物
  - 新可执行文件：`bin/svc_presence`
  - 路由表存储：Redis（建议）
- 验收标准
  - 用户 A、B 连接在不同网关实例，A 发消息/触发事件时 B 可收到推送

### 阶段 3：消息服务拆分（第 5~7 周）
**目标**：把消息写入、会话更新、投递逻辑从单体中抽离为独立服务。
- 工作内容
  - 拆出 `svc-message`（写入 + 查询）
  - 网关与 API 调用 `svc-message` 完成写入
  - 事件通知：写入后通知 `svc-presence/gateway-ws` 推送
- 交付物
  - 新可执行文件：`bin/svc_message`
  - 内部 RPC 接口定义（请求/响应 DTO）
- 验收标准
  - 发送消息可落库、会话更新、对端实时推送、离线后可拉取

### 阶段 4：按业务域继续拆分（第 8~10 周）
**目标**：联系人、群组、媒体等服务独立，形成“多服务 + 网关”结构。
- 工作内容
  - `svc-user`、`svc-contact`、`svc-group`、`svc-media` 拆分
  - 数据库访问边界清晰：每个服务仅访问自己的表/视图（必要时做拆库准备）
- 交付物
  - 对应服务可执行文件与部署配置
- 验收标准
  - 核心业务链路在多服务下完整可用

### 阶段 5：可观测、压测与可靠性（第 11~12 周）
**目标**：上线前的工程化补齐。
- 工作内容
  - 统一日志字段、请求 ID/trace id（最小实现）
  - 关键指标：连接数、消息 QPS、失败率、延迟、队列堆积
  - 压测：使用现有 `scripts/bench` 扩展分布式场景
  - 容错：重试策略、熔断/限流（网关侧优先）
- 交付物
  - 压测报告与容量建议
  - 故障演练 checklist
- 验收标准
  - 在目标压测指标下稳定运行（由团队设定阈值）

## 5. 技术方案要点（落地建议）

### 5.1 服务发现与负载均衡
- ZooKeeper 注册信息建议包含：`service_name`、`instance_id`、`host:port`、权重、机房/标签。
- 客户端侧负载均衡：优先复用现有 `core/net/streams/load_balance`（如有）或实现简单 round-robin。

补充落地建议：
- 注册节点使用 **临时节点（EPHEMERAL）**，实例断连自动下线。
- 服务路径建议：`/services/{service_name}/{instance_id}`，节点数据存 `host:port` + metadata（json）。
- 发现侧需要 watch children 变化，自动刷新本地实例列表（现有 `ZKServiceDiscovery` 已具备 watch 能力）。

### 5.2 跨网关推送
- presence 记录：`user_id -> {gateway_instance_id, last_seen, conn_id}`，并用 TTL 清理。
- 推送路径：`svc-message`（或业务服务） → 查 presence → RPC 到目标 `gateway-ws` → websocket push。

补充落地建议：
- `gateway_instance_id` 建议等于服务发现的 `instance_id`，避免二义性。
- presence 建议以 Redis 为准：`presence:{uid} -> {instance_id, device_id, last_seen}`（可多设备存 set/hash）。
- 需要定义“网关间投递 RPC”：例如 `DeliverToUser(uid, payload)`，由目标网关执行本地推送。

### 5.3 数据拆分原则
- 初期允许共享一个 MySQL（逻辑隔离），中期按服务拆 schema，后期按服务拆库。
- 禁止跨服务直接读写对方表：通过 RPC/事件获取数据。

### 5.4 消息服务（幂等、存储、离线与多端同步）

落地清单（按重要性）：
1. **幂等与去重**：为每条客户端消息引入 `client_msg_id`（或 `msg_id`），服务端保证重复提交不产生重复写入。
2. **写入与投递解耦**：短期同进程异步队列（线程池任务）即可；中期引入 MQ（Kafka/RabbitMQ 等）做削峰与重试。
3. **离线消息**：目标用户不在线时进入离线存储；上线后由 sync 拉取或触发补推。
4. **多端同步**：为用户维护 `device_id` 维度的游标（`seq_id`），推送时对同一用户的多设备广播（可排除发送方设备）。

### 5.5 会话与在线状态管理

- 网关负责“连接生命周期”（connect/heartbeat/disconnect）与本地连接表。
- `svc-presence` 负责“用户 -> 网关实例”的全局路由；支持 TTL 与心跳续租。
- 心跳策略：WS 心跳更新 `last_seen`；presence 端按 TTL 自动过期。

### 5.6 ID 生成与分片（中期能力）

当前工程内已有分布式 ID 的组件雏形（例如 `IdWorker`），但也有注释说明暂时改用数据库自增。

建议按阶段处理：
- 阶段 1~3：先用 DB 自增或现有策略，保证正确性与可运维。
- 阶段 4~5：在“跨库/分片”前，再引入雪花 ID（需要 machine/datacenter 分配与时钟回拨处理）。

分库分表建议（计划级别，不在本阶段强行落地）：
- 用户表按 `user_id % N` 分片
- 消息表按时间（按月）+ 接收方维度做分片或分区（结合查询模式确定）

### 5.7 监控与运维（最小可用）

建议最小指标集：
- 网关：在线连接数、鉴权失败率、推送成功率、推送延迟、消息入站 QPS
- 消息服务：写入 QPS、写入失败率、DB 延迟、离线堆积量、重试次数
- presence：在线用户数、路由命中率、过期数

建议统一：
- `request_id/trace_id`（网关生成并透传到后端服务日志）
- 日志字段规范：service_name、instance_id、uid、device_id、msg_id

### 5.8 部署与配置（建议形态）

本仓库已有脚本与配置目录，可按“多进程 + 多配置目录”组织：
- `bin/config/gateway_ws/*`
- `bin/config/gateway_http/*`
- `bin/config/svc_message/*`
- `bin/config/svc_presence/*`

容器化（可选）建议使用 docker-compose/helm，核心依赖：MySQL、Redis、ZooKeeper、（可选 MQ）。

## 6. 项目管理

### 6.1 角色与分工（建议）
- 架构/负责人：整体演进、接口治理、里程碑验收
- 网关负责人：gateway-http / gateway-ws、鉴权、限流、路由
- 消息负责人：消息写入、查询、投递、离线
- 基础设施负责人：ZK/Redis/MySQL、部署脚本、可观测

### 6.2 风险与对策
- 风险：跨网关推送复杂、状态一致性难
  - 对策：优先落地 presence + 路由；推送失败可降级为客户端轮询拉取
- 风险：拆分导致接口爆炸、调试困难
  - 对策：先把 RPC 接口收敛为“按域服务”；引入统一 trace id
- 风险：性能回退
  - 对策：阶段性压测与回归；先保证正确性再优化

## 7. 验收标准（最终）
- 多实例 `gateway-ws` 可扩容，跨实例推送可用
- 消息写入与查询在 `svc-message` 内闭环，数据库一致性满足需求
- 服务发现稳定：实例上下线可自动感知
- 关键链路可观测：能定位请求失败原因与耗时

---

## 附：建议的可执行文件命名（示例）
- `bin/gateway_ws`
- `bin/gateway_http`
- `bin/svc_presence`
- `bin/svc_message`
- `bin/svc_user`
- `bin/svc_contact`
- `bin/svc_group`
- `bin/svc_media`

> 命名仅供参考，最终以团队约定为准。

## 8. 任务列表与进度跟踪

- [x] **阶段 0：集群基础环境搭建**
    - [x] 建立分布式演进基础环境
    - [x] 修复 ZK 注册并发创建冲突 Bug
- [x] **阶段 1：网关分离 (Gateway Separation)**
    - [x] 创建 `gateway_ws` 和 `gateway_http` 专用入口程序
    - [x] 建立独立的配置目录：`bin/config/gateway_ws` 和 `bin/config/gateway_http`
    - [x] 设置专用的日志与工作目录，避免文件冲突
    - [x] 验证网关可以独立启动、监听端口并在 ZK 注册
    - [x] 编写 `scripts/gateways_run.sh` 专用启停脚本
- [ ] **阶段 2：在线路由服务抽离 (Presence Service Extraction)**
    - [ ] 设计分布式在线状态存储结构（Redis + ZK）
    - [ ] 实现跨网关的消息推送 RPC 接口
    - [ ] 改造 `WsGatewayModule` 使用 `svc-presence` 进行路由
- [ ] **阶段 3：消息服务拆分 (Message Service Extraction)**
    - [ ] 提取消息写入与离线存储逻辑为独立服务
    - [ ] 实现消息写入的幂等性校验
- [ ] **阶段 4：业务域服务拆分 (Business Service Sharding)**
- [ ] **阶段 5：监控、治理与性能压测**
